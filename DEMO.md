# HippoRAG 演示指南

## 目录

1. [快速开始](#快速开始)
2. [测试场景](#测试场景)
3. [工作原理](#工作原理)
4. [预期结果对比](#预期结果对比)
5. [核心技术](#核心技术)
6. [参数调优](#参数调优)

---

## 快速开始

### 环境配置

确保 `.env` 文件已配置：

```bash
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.agicto.cn/v1
HTTPS_PROXY=http://127.0.0.1:7890
```

### 运行演示

```bash
# 传统 RAG
make rag

# HippoRAG
make hippo
```

---

## 测试场景

### 测试文档集

项目提供两个测试文档集：

**1. 基础文档集（8个文档）**

用于快速测试和理解基本原理：

1. 阿尔伯特·爱因斯坦是著名的物理学家
2. 爱因斯坦于1879年3月14日出生于德国乌尔姆
3. 他在1905年发表了相对论
4. 19世纪是指1801年到1900年这段时期
5. 爱因斯坦在1921年获得诺贝尔物理学奖
6. 爱因斯坦有个同学叫小明
7. 小明生于1996年
8. 小明毕业于2018年

**2. 扩展文档集（60个文档）**

包含 8 个核心文档 + 52 个干扰文档，用于测试抗噪音能力。

干扰文档包括：
- 其他科学家（牛顿、居里夫人、达尔文等）
- 历史事件（一战、二战、法国大革命等）
- 地理信息（德国、柏林、巴黎等）
- 教育机构（哈佛、牛津、剑桥等）
- 时间相关（20世纪、21世纪等）

### 测试问题

**问题 1：爱因斯坦出生于哪个世纪？**

- **需要的文档**：文档2（1879年）+ 文档4（19世纪定义）
- **推理过程**：1879年 → 在1801-1900年之间 → 19世纪
- **难点**：需要结合两个文档进行推理

**问题 2：爱因斯坦的同学毕业的时候年龄是多少？**

- **需要的文档**：文档6（同学小明）+ 文档7（1996年）+ 文档8（2018年）
- **推理过程**：小明 → 1996年出生 → 2018年毕业 → 22岁
- **难点**：需要三跳推理，且在噪音环境下容易被"大学"相关文档干扰

---

## 工作原理

### 传统 RAG 流程

```
文档输入
  ↓
向量化
  ↓
向量存储
  ↓
查询输入
  ↓
向量化查询
  ↓
余弦相似度搜索
  ↓
Top-K 文档
  ↓
LLM 生成答案
```

**特点**：
- ✅ 简单直接
- ✅ 速度快
- ❌ 只考虑直接相似度
- ❌ 无法发现隐含关系
- ❌ 容易被相似但不相关的文档误导

### HippoRAG 流程

**索引阶段**：

```
文档输入
  ↓
文档分块
  ↓
OpenIE 提取（实体 + 关系三元组）
  ↓
构建知识图谱
  ├─ 节点：文档块 + 实体
  └─ 边：passage（块↔实体）+ fact（实体↔实体）+ synonymy（同义实体）
  ↓
向量化存储
  ├─ chunk_embeddings（文档块）
  ├─ entity_embeddings（实体）
  └─ fact_embeddings（事实三元组）
```

**检索阶段**：

```
查询输入
  ↓
查询向量化（query_to_fact + query_to_passage）
  ↓
事实检索（在 fact_embeddings 中搜索）
  ↓
LLM 重排序（Recognition Memory）
  ↓
密集段落检索 DPR（在 chunk_embeddings 中搜索）
  ↓
图搜索与 PPR
  ├─ 从事实中提取实体权重
  ├─ 合并段落权重
  └─ PPR 算法在图上传播
  ↓
Top-K 文档块
  ↓
LLM 生成答案
```

**特点**：
- ✅ 知识图谱 + 向量检索
- ✅ 支持多跳推理
- ✅ 能发现间接关联
- ✅ 抗噪音能力强
- ❌ 索引慢（需要 OpenIE）
- ❌ 检索慢（需要 PPR）

---

## 预期结果对比

### 问题 1：爱因斯坦出生于哪个世纪？

**传统 RAG**：
- 检索结果：文档2（出生日期）、文档5（诺贝尔奖）、文档1（物理学家）
- 问题：❌ 可能遗漏文档4（19世纪定义）
- 原因：文档4不包含"爱因斯坦"，向量相似度低
- 答案质量：⚠️ 可能无法准确回答

**HippoRAG**：
- 检索结果：文档4（19世纪定义）、文档2（出生日期）、文档1（物理学家）
- 优势：✅ 通过知识图谱发现"1879"和"19世纪"的关联
- 答案质量：✅ 准确回答"19世纪"

### 问题 2：爱因斯坦的同学毕业的时候年龄是多少？

**传统 RAG（8个文档）**：
- 检索结果：文档6（同学小明）、文档2（爱因斯坦出生）、文档1（物理学家）
- 问题：❌ 遗漏文档7（1996年）和文档8（2018年）
- 原因：查询中的"毕业"让向量检索偏向爱因斯坦相关文档
- 答案质量：❌ 无法回答

**传统 RAG（60个文档）**：
- 检索结果：文档6（同学小明）、大学相关干扰文档...
- 问题：❌ 被"大学"、"毕业"相关的干扰文档误导
- 答案质量：❌ 无法回答

**HippoRAG（8个文档）**：
- 检索结果：文档6、文档7、文档8（所有必要文档）
- 优势：✅ PPR 传播找到所有相关文档
- 答案质量：✅ 准确回答"22岁"

**HippoRAG（60个文档）**：
- 检索结果：通过事实检索 + LLM 重排序 + DPR + PPR，找到所有必要文档
- 优势：✅ 抗噪音能力强，不被干扰文档误导
- 答案质量：✅ 准确回答"22岁"

---

## 核心技术

### 1. OpenIE 信息抽取

**作用**：从文档中提取结构化知识

**输入**：文档文本

**输出**：
- 实体列表：["爱因斯坦", "1879年", "德国", "乌尔姆"]
- 三元组：[("爱因斯坦", "出生于", "1879年"), ("爱因斯坦", "出生在", "乌尔姆")]

**实现**：使用 LLM 进行提取

### 2. 知识图谱

**节点类型**：
- `chunk`：文档块节点
- `entity`：实体节点

**边类型**：
- `passage`：文档块 ↔ 实体（双向）
- `fact`：实体 ↔ 实体（双向）
- `synonymy`：同义实体（基于向量相似度）

**为什么需要双向边？**
- PPR 从实体节点开始传播
- 双向边让分数能传播回文档块
- 支持双向推理

### 3. Personalized PageRank (PPR)

**作用**：在知识图谱上传播分数，找到间接相关的文档

**过程**：
1. 初始化：给种子节点（相关实体）分配权重
2. 迭代传播：沿着图的边传播分数
3. 收敛：分数稳定后停止
4. 排序：按 PPR 分数排序文档块

**参数**：
- `damping`：阻尼系数（默认 0.5），控制传播范围
- `maxIter`：最大迭代次数（默认 100）
- `tolerance`：收敛阈值（默认 1e-6）

**优势**：
- 能找到间接相关的节点
- 考虑整个图的结构
- 支持多跳推理

### 4. Recognition Memory（LLM 重排序）

**作用**：用 LLM 对候选事实进行重排序，提高精确度

**过程**：
1. 向量检索找到 Top-K 候选事实
2. 构建重排序 prompt
3. LLM 理解语义后重新排序
4. 使用重排序后的结果

**优势**：
- 弥补向量相似度的不足
- LLM 能理解更深层的语义关系
- 减少噪音，提高相关性

### 5. 密集段落检索（DPR）

**作用**：直接在文档块向量库中搜索相关段落

**过程**：
1. 查询向量化（query_to_passage）
2. 在 chunk_embeddings 中搜索
3. 返回 Top-K 相似段落

**作用**：
- 给文档块节点分配初始权重
- 与实体权重合并后进行 PPR
- 平衡结构化知识和原始文本

---

## 参数调优

### TopKEntities（实体数量）

**作用**：PPR 的种子节点数量

**影响**：
- 越大 → 召回率越高，但检索时间越长
- 越小 → 速度快，但可能遗漏关键实体

**推荐配置**：

| 文档集大小 | TopKEntities |
|-----------|-------------|
| < 20 | 10 |
| 20-50 | 15 |
| 50-100 | 20 |
| > 100 | 30 |

**注意**：TopKEntities 不影响 LLM 上下文长度！

### TopKChunks（文档块数量）

**作用**：最终给 LLM 的文档数量

**影响**：
- 越大 → 信息越完整，但 LLM 成本越高
- 越小 → 成本低，但可能信息不足

**推荐配置**：

| 场景 | TopKChunks |
|------|-----------|
| 简单查询 | 5 |
| 中等查询 | 10 |
| 复杂查询 | 15 |

### PPRDamping（阻尼系数）

**作用**：控制 PPR 传播范围

**影响**：
- 越小（如 0.3）→ 传播更广，能找到更远的节点
- 越大（如 0.7）→ 传播更集中，只关注近邻

**推荐配置**：
- 默认：0.5
- 需要更广传播：0.3
- 需要更集中：0.7

---

## 性能对比

### 索引性能

| 方法 | 100 个文档 | 说明 |
|------|-----------|------|
| 传统 RAG | ~10 秒 | 只需向量化 |
| HippoRAG | ~5 分钟 | 需要 OpenIE + 图构建 |

### 检索性能

| 方法 | 单次查询 | 说明 |
|------|---------|------|
| 传统 RAG | ~0.5 秒 | 单次向量搜索 |
| HippoRAG | ~2 秒 | 事实检索 + LLM 重排序 + DPR + PPR |

### 准确性对比

| 场景 | 传统 RAG | HippoRAG |
|------|---------|----------|
| 简单事实查询 | ✅ 好 | ✅ 好 |
| 单跳推理 | ⚠️ 中等 | ✅ 好 |
| 多跳推理 | ❌ 差 | ✅ 好 |
| 噪音环境 | ❌ 差 | ✅ 好 |

---

## 适用场景

### 传统 RAG 适合

- ✅ 简单的事实查询
- ✅ 文档和查询直接相关
- ✅ 对速度要求高
- ✅ 资源受限
- ✅ 文档集较小（< 100）

### HippoRAG 适合

- ✅ 需要推理的复杂查询
- ✅ 多跳问题（需要结合多个文档）
- ✅ 知识密集型任务
- ✅ 对准确性要求高
- ✅ 噪音环境（大量干扰文档）

---

## 故障排查

### 问题：检索结果为空

**可能原因**：
1. 图的边是单向的
2. PPR 参数不合适
3. 实体提取失败

**解决方案**：
- 检查图构建时是否添加了双向边
- 调整 PPR 参数（damping, maxIter）
- 查看 OpenIE 提取的实体数量

### 问题：检索到的文档不相关

**可能原因**：
1. TopKEntities 太小，遗漏关键实体
2. TopKChunks 太小，遗漏关键文档
3. 噪音实体权重过高

**解决方案**：
- 增加 TopKEntities（如 10 → 20）
- 增加 TopKChunks（如 5 → 10）
- 降低 PPRDamping（如 0.5 → 0.3）

### 问题：API 调用失败

**可能原因**：
1. API Key 无效
2. 代理配置错误
3. Base URL 错误

**解决方案**：
- 检查 .env 文件中的 OPENAI_API_KEY
- 测试代理：`curl -x http://127.0.0.1:7890 https://api.agicto.cn/v1/models`
- 确认 OPENAI_BASE_URL 正确

---

## 实验建议

### 基础实验

1. 使用基础文档集（8个）测试两个问题
2. 观察传统 RAG 和 HippoRAG 的检索差异
3. 理解 PPR 传播的作用

### 进阶实验

1. 使用扩展文档集（60个）测试
2. 对比不同 TopKEntities 的效果
3. 调整 PPR 参数观察变化
4. 尝试自己的文档和问题

### 参数调优实验

1. 固定其他参数，只改变 TopKEntities
2. 观察召回率和精确率的变化
3. 找到最佳平衡点

---

## 参考资料

- [HippoRAG 论文](https://arxiv.org/abs/2405.14831)
- [Personalized PageRank](https://en.wikipedia.org/wiki/PageRank#Personalized_PageRank)
- [OpenIE](https://nlp.stanford.edu/software/openie.html)

---

**提示**：运行演示前确保代理和 API 配置正确！
